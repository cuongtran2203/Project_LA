{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=sqlite3.connect(\"tvmaze.sqlite\")\n",
    "df_info=pd.read_sql_query(\"SELECT * from tvmaze\",con)\n",
    "df_genre=pd.read_sql_query(\"SELECT * from tvmaze_genre\",con)\n",
    "df_casting=pd.read_sql_query(\"SELECT * from tvmaze_casting\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_genre[\"genre\"]\n",
    "df_info[\"description\"].dropna(axis=0)\n",
    "df_info['description'].fillna('', inplace=True)\n",
    "len(df_genre[\"genre\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    text = text.replace('<p>', '')\n",
    "    text = text.replace('</p>', '')\n",
    "    text = text.replace('</b>', '')\n",
    "    text = text.replace('<b>', '')\n",
    "    text = text.replace(r'\\W', '')\n",
    "    text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        under the dome is the story of a small town th...\n",
       "1        you are being watched. the government has a se...\n",
       "2        based on the critically acclaimed series of no...\n",
       "3        after a violent shipwreck, billionaire playboy...\n",
       "4        touch darkness and darkness touches you back. ...\n",
       "                               ...                        \n",
       "65983    a cooperative drama between a fraudster who ca...\n",
       "65984                                                     \n",
       "65985    chen jun, a pseudo-otaku who aspires to eat an...\n",
       "65986    a professional killer decides to retract from ...\n",
       "65987    this gripping three-part series explores one o...\n",
       "Name: description, Length: 65988, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info[\"description\"]=df_info[\"description\"].apply(lambda x: remove_tags(x))\n",
    "df_info[\"description\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list=df_info[\"tvmaze_id\"].to_list()\n",
    "\n",
    "df_genre[\"genre\"]\n",
    "df_merged=pd.merge(df_info,df_genre,on=\"tvmaze_id\",how=\"inner\")\n",
    "df_merged.to_csv(\"datafillter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/621 [=====>........................] - ETA: 8:21 - loss: 2.8019 - accuracy: 0.2134"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('datafillter.csv')\n",
    "data=data.dropna()\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "X = data['description']\n",
    "y = data['genre']\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=200)\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(28, activation='softmax'))  # Adjust the output dimension based on your number of genres\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: %.2f\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Text\n",
      "0  This is an example</p>\n",
      "1     Some text with  tag\n",
      "2       Another  example \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "# df = pd.DataFrame(your_data)\n",
    "\n",
    "# Tạo một DataFrame mẫu\n",
    "data = {'Text': ['<p>This is an example</p>', 'Some text with </b> tag', 'Another <p> example </b>']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Loại bỏ các chuỗi <p> và </b> từ cột 'Text'\n",
    "df['Text'] = df['Text'].str.replace('<p>', '').str.replace('</b>', '')\n",
    "\n",
    "# In DataFrame sau khi loại bỏ các chuỗi\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello', 'there', 'good', 'man!'], ['It', 'is', 'quite', 'windy', 'in', 'London'], ['How', 'is', 'the', 'weather', 'today?']]\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "print(tokenized_corpus)\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
